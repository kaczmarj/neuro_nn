{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement highres3dnet\n",
    "\n",
    "Paper: https://arxiv.org/abs/1707.01992\n",
    "\n",
    "Preprocessing steps\n",
    "---\n",
    "- Anatomical\n",
    "    1. Load.\n",
    "    1. Squeeze data array.\n",
    "    1. Check for 3 dimensions.\n",
    "    1. Add one color channel.\n",
    "- Labels\n",
    "    1. Load.\n",
    "    1. Squeeze data array.\n",
    "    1. Check for 3 dimensions.\n",
    "    1. One-hot encode.\n",
    "   \n",
    "Loading steps\n",
    "---\n",
    "1. Load anatomical and labels.\n",
    "1. Get blocks for each array.\n",
    "1. Feed those blocks into the model in batches.\n",
    "\n",
    "Questions\n",
    "---\n",
    "1. Should we impose a restriction, where batch size must be evenly divisible by number of blocks (viewpoints) that are in a volume? Probably.\n",
    "\n",
    "Todo\n",
    "---\n",
    "- Look into [`keras.utils.multi_gpu_model`](https://keras.io/utils/#multi_gpu_model) to train on multiple GPUs. This is only available for the TensorFlow backend.\n",
    "- Learn about one-hot encoding / decoding. Encode the array of labels with `K.one_hot()`. Decode the predictions with `K.argmax()`. `K.one_hot()` simply calls `tf.one_hot()`, so this would restrict us to the TensorFlow backend, which is fine for now.\n",
    "\n",
    "\n",
    "Notes\n",
    "---\n",
    "- NiftyNet trains on a sliding window over the 3D data. This should have that ability to lower GPU memory requirements.\n",
    "\n",
    "Future considerations\n",
    "---\n",
    "- Modify `highres3dnet` to use ResNeXt architechture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from sklearn.feature_extraction.image import extract_patches\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from highres3dnet import dice_coef, dice_loss, HighRes3DNet\n",
    "\n",
    "logger = logging.getLogger(name=__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 16,\n",
    "    'block_shape': (64, 64, 64, 1),  # size of input to model.\n",
    "    'image_data_format': 'channels_last',\n",
    "    'n_classes': 2,\n",
    "    'volume_shape': (256, 256, 256, 1),\n",
    "}\n",
    "\n",
    "K.set_image_data_format(config['image_data_format'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_filepath = \"/om/user/jakubk/nobrainer-code/niftynet_to_keras/t1_brainmask.csv\"\n",
    "df_input = pd.read_csv(input_filepath)\n",
    "df_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HighRes3DNet(n_classes=config['n_classes'], input_shape=config['block_size'])\n",
    "\n",
    "# Use multiple GPUs.\n",
    "# gpu_ids = [int(ss) for ss in os.environ['CUDA_VISIBLE_DEVICES'].split(',')]\n",
    "# model = keras.utils.multi_gpu_model(model, gpus=gpu_ids)\n",
    "\n",
    "model.input_shape\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 0\n",
    "offset = 65\n",
    "data_input = load_volume(df_input.loc[row, 't1'])\n",
    "# data_input = data_input[offset:volume_input_shape[0]+offset, \n",
    "#                         offset:volume_input_shape[1]+offset, \n",
    "#                         offset:volume_input_shape[2]+offset]\n",
    "\n",
    "_validate_dims(data_input)\n",
    "# data_input = _reshape(data_input, volume_input_shape)\n",
    "# data_input = np.expand_dims(data_input, 0)\n",
    "\n",
    "data_test = load_volume(df_input.loc[row, 'brainmask'])\n",
    "# data_test = data_test[offset:volume_input_shape[0]+offset, \n",
    "#                       offset:volume_input_shape[1]+offset, \n",
    "#                       offset:volume_input_shape[2]+offset]\n",
    "_validate_dims(data_test)\n",
    "\n",
    "data_test = K.one_hot(data_test, num_classes=2)\n",
    "\n",
    "labels = K.stack((data_test,))\n",
    "\n",
    "labels = K.stack((data_test,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', dice_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.fit(data_input, data_test, batch_size=1, verbose=1)\n",
    "model.fit(data_input, labels_np, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def load_volume(filepath, return_affine=False, c_contiguous=True):\n",
    "    \"\"\"Return data given filepath to volume. Optionally return affine array.\n",
    "    \n",
    "    Making the data array contiguous takes more time during loading, but this\n",
    "    ultimately saves time when viewing blocks of data with `skimage`.\n",
    "    \"\"\"\n",
    "    img = nib.load(filepath)\n",
    "    data = np.asarray(img.dataobj)\n",
    "    if c_contiguous:\n",
    "        data = np.ascontiguousarray(data)\n",
    "    if return_affine:\n",
    "        return data, img.affine\n",
    "    return data\n",
    "\n",
    "\n",
    "def _validate_dims(a, ndim=3):\n",
    "    \"\"\"Raise `ValueError` if Numpy array `a` has fewer than `ndims` dimensions.\"\"\"\n",
    "    if a.ndim != ndim:\n",
    "        msg = \"Expected {} dimensions but got {}.\".format(ndim, a.ndim)\n",
    "        raise ValueError(msg.format(a.ndim))\n",
    "\n",
    "\n",
    "def get_blocks(a, block_shape):\n",
    "    \"\"\"\n",
    "    Examples\n",
    "    --------\n",
    "    >>> arr = np.ones((4*4)).reshape(4, 4)\n",
    "    >>> blocks = get_blocks(arr, (2, 2))\n",
    "    >>> blocks.shape\n",
    "    (4, 2, 2)\n",
    "    >>> np.lib.stride_tricks.as_strided(blocks, shape=arr.shape, strides=arr.strides)\n",
    "    \"\"\"\n",
    "    return skimage.util.view_as_blocks(a, block_shape).reshape(-1, *block_shape)\n",
    "\n",
    "\n",
    "def get_num_blocks(volume_shape, block_shape):\n",
    "    \"\"\"Return number of non-overlapping blocks of `block_shape` in `volume_shape`.\"\"\"\n",
    "    if len(volume_shape) != len(block_shape):\n",
    "        raise ValueError(\"Volume and batch must have same number of dimensions.\")\n",
    "    return np.divide(volume_shape, block_shape).prod()\n",
    "\n",
    "\n",
    "class VolumeSequence(tf.keras.utils.Sequence):\n",
    "    \"\"\"\"\"\"\n",
    "    def __init__(self, x_files, y_files, batch_size, volume_shape, \n",
    "                 block_shape=None):\n",
    "        self.x, self.y = x_files, y_files\n",
    "        self.batch_size = batch_size\n",
    "        self.volume_shape = volume_shape\n",
    "        self.block_shape = block_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        # return math.ceil(len(self.x) / self.batch_size / self._volumes_per_batch)\n",
    "        return math.ceil(len(self.x) * self._blocks_per_volume / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Assumes that each input volume is the same shape.\"\"\"\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        \n",
    "\n",
    "        return (\n",
    "\n",
    "#             np.array([resize(imread(file_name), (200, 200)) for file_name in batch_x]), \n",
    "#             np.array(batch_y)\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def _blocks_per_volume(self):\n",
    "        \"\"\"Number of non-overlapping blocks per volume.\"\"\"\n",
    "        return get_num_blocks(volume_shape=self.volume_shape, \n",
    "                              block_shape=self.block_shape)\n",
    "\n",
    "    @property\n",
    "    def _volumes_per_batch(self):\n",
    "        return self.batch_size / self._blocks_per_volume\n",
    "        # return get_volumes_per_batch(num_blocks=self._blocks_per_volume, \n",
    "        #                              batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = VolumeSequence(x_files=df_input['t1'], \n",
    "                    y_files=df_input['brainmask'], \n",
    "                    batch_size=config['batch_size'], \n",
    "                    volume_shape=config['volume_shape'], \n",
    "                    block_shape=config['block_shape'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __getitem__ should find the correct volume(s) and return the arrays from that.\n",
    "# batch 0 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa._blocks_per_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa._volumes_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
