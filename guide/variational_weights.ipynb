{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model with variational weights\n",
    "\n",
    "Nobrainer implements variational convolutions. These layers, which can be used like any other Keras layer, learn gaussian distributions instead of scalar weights. In other words, these layers learn a mean and a standard deviation. This increases the memory footprint of the model, but variational convolutions enable things like [Distributed Weight Consolidation](https://arxiv.org/abs/1805.10863) and [measuring model uncertainty](https://arxiv.org/abs/1812.01719).\n",
    "\n",
    "In this notebook, we will train a variational MeshNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMP\n",
    "import sys; sys.path.append('..'); del sys\n",
    "\n",
    "import nobrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset of data\n",
    "\n",
    "This assumes you have downloaded sample data in 'getting started' notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 1\n",
    "batch_size = 10\n",
    "volume_shape = (256, 256, 256)\n",
    "block_shape = (64, 64, 64)\n",
    "\n",
    "dataset = nobrainer.volume.get_dataset(\n",
    "    file_pattern='tfrecords/data_shard-*.tfrecords',\n",
    "    n_classes=n_classes,\n",
    "    batch_size=batch_size,\n",
    "    volume_shape=volume_shape,\n",
    "    block_shape=block_shape,\n",
    "    augment=False,\n",
    "    n_epochs=None,\n",
    "    shuffle_buffer_size=5)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = nobrainer.volume.get_steps_per_epoch(\n",
    "    n_volumes=10, \n",
    "    volume_shape=volume_shape, \n",
    "    block_shape=block_shape, \n",
    "    batch_size=batch_size)\n",
    "\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate model\n",
    "\n",
    "Setting the flag `is_mc` to `True` will cause the model to sample a weight from its learned distributions. It will sample a different weight for every item in every minibatch.\n",
    "\n",
    "Setting `is_mc` to `False` will cause the model to use the mean of every weight distribution (i.e., the most likely sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = nobrainer.models.meshnet_vwn(\n",
    "    n_classes, \n",
    "    input_shape=(*block_shape, 1), \n",
    "    filters=21, \n",
    "    is_mc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model\n",
    "\n",
    "You _must_ use the loss `nobrainer.losses.Variational` to train variational models. It is the only loss function in nobrainer that is aware of gaussian weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(\n",
    "    tf.keras.optimizers.Adam(1e-04), \n",
    "    loss=nobrainer.losses.Variational(model=model, n_examples=256**3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "Here, we train on one GPU, but this model can be trained on multiple GPUs or a TPU. Please refer to other notebooks in the Nobrainer guide to learn how to train models on multiple GPUs or TPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "\n",
    "For sake of simplicity, we predict on our training data. Never do this in practice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.predict(dataset, steps=steps_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nb]",
   "language": "python",
   "name": "conda-env-nb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
